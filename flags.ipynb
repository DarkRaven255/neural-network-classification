{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from random import shuffle\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(22)\n",
    "error_tab = []\n",
    "lr_tab = []\n",
    "acc_tab = []\n",
    "\n",
    "dfu = pd.read_csv('flagdata.csv', header=None)\n",
    "\n",
    "columns = ['Landmass', 'Zone', 'Area', 'Population', 'Language', 'Religion', 'Bars', 'Stripes', 'Colours', 'Red', 'Green', 'Blue', 'Gold', 'White', 'Black', 'Orange', 'MainHue', 'Circles', 'Crosses', 'Saltires', 'Quarters', 'Sunstars', 'Crescent', 'Triangle', 'Icon', 'Animate', 'Text', 'TopLeft', 'BotRight']\n",
    "dfu.columns = columns\n",
    "\n",
    "# dfu.info()\n",
    "\n",
    "df=dfu\n",
    "df=((df-df.min())/(df.max()-df.min()))\n",
    "df[\"Religion\"]=dfu[\"Religion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "valid = df.sample(20)\n",
    "train = df.drop(valid.index)\n",
    "\n",
    "x = train.drop('Religion', axis=1).values\n",
    "labels = train['Religion']\n",
    "y = pd.get_dummies(train['Religion']).values\n",
    "\n",
    "xt = valid.drop('Religion', axis=1).values\n",
    "labels = valid['Religion']\n",
    "yt = pd.get_dummies(valid['Religion']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# valid.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    n_x = 28 # input layer\n",
    "    n_y = 8 # output layer\n",
    "    return (n_x, n_y)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#   # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "#   return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def deriv_sigmoid(x):\n",
    "#   # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "#   fx = sigmoid(x)\n",
    "#   return fx * (1 - fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h1, n_h2, n_y):\n",
    "    W1 = np.random.randn(n_x,n_h1)\n",
    "    W2 = np.random.randn(n_h1,n_h2)\n",
    "    W3 = np.random.randn(n_h2,n_y)\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    \n",
    "    # Layer 1\n",
    "    Z1 = np.dot(X, W1)\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    # Layer 2\n",
    "    Z2 = np.dot(A1, W2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    # Layer 3\n",
    "    Z3 = np.dot(A2, W3)\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2,\n",
    "             \"Z3\": Z3,\n",
    "             \"A3\": A3}\n",
    "    \n",
    "    return A3, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(A3, Y):\n",
    "    cost = 0.5 * np.sum(np.power(A3-Y, 2))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(output_vec, test_vec):\n",
    "    equals = np.equal(np.argmax(test_vec, axis=1), np.argmax(output_vec, axis=1))\n",
    "    acc = np.mean(equals)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def adapt_learning_rate(learning_rate, xi_d, xi_i, er_r, cost, prev_cost):\n",
    "    if cost > er_r*prev_cost:\n",
    "        learning_rate*=xi_d\n",
    "    elif cost < prev_cost:\n",
    "        learning_rate*=xi_i\n",
    "    prev_cost = cost\n",
    "    return learning_rate, prev_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "        \n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    A3 = cache['A3']\n",
    "    \n",
    "    Z1 = cache['Z1']\n",
    "    Z2 = cache['Z2']\n",
    "    \n",
    "    ########## Layer 3\n",
    "    delta3 = A3-Y\n",
    "    dW3 = np.dot(A2.T, delta3)\n",
    "    \n",
    "    ########## Layer 2\n",
    "    delta2 = np.dot(delta3, W3.T) * sigmoid_prime(Z2)\n",
    "    dW2 = np.dot(A1.T, delta2)\n",
    "    \n",
    "    ########## Layer 1\n",
    "    delta1 = np.dot(delta2, W2.T) * sigmoid_prime(Z1)\n",
    "    dW1 = np.dot(X.T, delta1)\n",
    "\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"dW2\": dW2,      \n",
    "             \"dW3\": dW3}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    dW2 = grads['dW2']\n",
    "    dW3 = grads['dW3']\n",
    "\n",
    "    W1 -= learning_rate * dW1\n",
    "    W2 -= learning_rate * dW2\n",
    "    W3 -= learning_rate * dW3\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h1, n_h2, er_r, xi_i, xi_d, num_iterations, learning_rate):\n",
    "    prev_cost = 1\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[1]\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h1, n_h2, n_y)\n",
    " \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    \n",
    "#     max_acc = 0;\n",
    "    \n",
    "    for epoch in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A3, cache\".\n",
    "        A3, cache = forward_propagation(X, parameters)\n",
    "\n",
    "        # Cost function. Inputs: \"A3, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(A3, Y)\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        \n",
    "        # ADAPTIVE LEARNING RATE:\n",
    "        learning_rate, prev_cost = adapt_learning_rate(learning_rate, xi_d, xi_i, er_r, cost, prev_cost)\n",
    "\n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "#         loss = -np.sum(y * np.log(A3))\n",
    "#         error_tab.append(cost)\n",
    "#         lr_tab.append(learning_rate)\n",
    "#         equals = np.equal(np.argmax(y, axis=1), np.argmax(A3, axis=1))\n",
    "#         acc = np.mean(equals)\n",
    "#         A3, cache = forward_propagation(xt, parameters)\n",
    "#         equals = np.equal(np.argmax(yt, axis=1), np.argmax(A3, axis=1))\n",
    "#         acc_t = np.mean(equals)\n",
    "#         acc_tab.append(acc)\n",
    "#         print(\"Cost after iteration %i: %f, accuracy: %f\" %(epoch, acc, acc_t))\n",
    "\n",
    "    return parameters, A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_model(x, y, 15, 20, 1.01, 1.01, 0.7, 3000, 1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40, 40, 0.9137931034482759, 0.45\n",
      "40, 41, 0.8505747126436781, 0.3\n",
      "40, 42, 0.6724137931034483, 0.55\n",
      "40, 43, 0.8793103448275862, 0.3\n",
      "40, 44, 0.7298850574712644, 0.3\n",
      "40, 45, 0.8103448275862069, 0.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0f206e941669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_h1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_number\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_h2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_number\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mer_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.04\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-87caf5ef1911>\u001b[0m in \u001b[0;36mnn_model\u001b[1;34m(X, Y, n_h1, n_h2, er_r, xi_i, xi_d, num_iterations, learning_rate)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Cost function. Inputs: \"A3, Y, parameters\". Outputs: \"cost\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-4edb79ff9776>\u001b[0m in \u001b[0;36mcompute_cost\u001b[1;34m(A3, Y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LAYERS SIZE\n",
    "n_number = list(range(40, 50, 1))\n",
    "acc_tab = np.zeros(shape=(100,100))\n",
    "for n_h1 in n_number:\n",
    "    for n_h2 in n_number:\n",
    "        parameters, A3 = nn_model(x, y, n_h1, n_h2, er_r = 1.04, xi_i = 1.05, xi_d = 0.7, num_iterations = 3000, learning_rate = 0.1)\n",
    "        acc = accuracy(output_vec = A3, test_vec = y)\n",
    "        A3, cache = forward_propagation(xt, parameters)\n",
    "        acc_t = accuracy(output_vec = A3, test_vec = yt)\n",
    "        print(\"{}, {}, {}, {}\".format(n_h1, n_h2, acc, acc_t))\n",
    "        acc_tab[n_h1-1, n_h2-1] = acc*acc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "fig = plt.figure(num=None, figsize=(6, 5), dpi=150, facecolor='w', edgecolor='k')\n",
    "X = np.linspace(1, 100, 100)\n",
    "Y = np.linspace(1, 100, 100)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlabel('2nd layer')\n",
    "ax.set_ylabel('1st layer')\n",
    "ax.set_zlabel('acc * acc_t')\n",
    "ax.plot_surface(X, Y, acc_tab, rstride=1, cstride=1, cmap='viridis', antialiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# XI_I XI_D\n",
    "xi_i_number = list(range(101, 131, 1))\n",
    "xi_d_number = list(range(71, 99, 1))\n",
    "acc_tab_xi = np.zeros(shape=(10,10))\n",
    "for n_h1 in n_number:\n",
    "    for n_h2 in n_number:\n",
    "        parameters, A3 = nn_model(x, y, n_h1, n_h2, er_r = 1.016, xi_i = 1.06, xi_d = 0.77, num_iterations = 4800, learning_rate = 0.01)\n",
    "        acc = accuracy(output_vec = A3, test_vec = y)\n",
    "        A3, cache = forward_propagation(xt, parameters)\n",
    "        acc_t = accuracy(output_vec = A3, test_vec = yt)\n",
    "        print(\"{}, {}, {}, {}\".format(n_h1, n_h2, acc, acc_t))\n",
    "        acc_tab[n_h1-1, n_h2-1] = acc*acc_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
